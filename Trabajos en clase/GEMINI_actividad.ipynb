{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5ZVm6CIouwgF"
      },
      "outputs": [],
      "source": [
        "%pip install -U -q google-genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "0xS2NWpqvWHX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "cliente = genai.Client(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "sL2CGPN7vvHj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EJERCICIO\n",
        "\n",
        "Escribí un texto corto sobre una experiencia personal en un transporte público en Buenos Aires.\n",
        "\n",
        "Luego, generá:\n",
        "\n",
        "- Un resumen.\n",
        "- Una clasificación de sentimiento.\n",
        "- Una lista de entidades nombradas."
      ],
      "metadata": {
        "id": "nOPQ22a63k0r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Texto de experiencia personal\n",
        "text_to_process = \"\"\"\n",
        "Ayer tomé el subte D en la estación Catedral rumbo a Palermo. El vagón estaba lleno y hacía mucho calor.\n",
        "Una señora mayor se descompuso y varias personas la ayudaron rápidamente. Un empleado del subte llegó enseguida y llamó al SAME.\n",
        "Me impresionó la solidaridad de la gente. Aunque fue una situación tensa, me fui con una sensación positiva.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "9FrAGtDHEnet"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_ID = \"gemini-2.0-flash\" # @param [\"gemini-2.0-flash-lite\",\"gemini-2.0-flash\",\"gemini-2.5-flash-preview-05-20\",\"gemini-2.5-pro-preview-05-06\"] {\"allow-input\":true, isTemplate: true}"
      ],
      "metadata": {
        "id": "msa42Srs1Mci"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1**. Resumen**"
      ],
      "metadata": {
        "id": "McLWCrzGEuat"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos el prompt en lenguaje natural para pedirle a Gemini que haga un resumen\n",
        "# Se inserta el texto original dentro del prompt con formato f-string\n",
        "prompt_resumen = f\"\"\"Resumí este texto en 2 oraciones de rápida lectura:\n",
        "\n",
        "Texto: {text_to_process}\n",
        "\"\"\"\n",
        "\n",
        "# Llamamos a Gemini (modelo definido en MODEL_ID) para generar contenido basado en el prompt\n",
        "# `contents` espera una lista de mensajes (en este caso, uno solo)\n",
        "respuesta = cliente.models.generate_content(model=MODEL_ID, contents=[prompt_resumen])\n",
        "\n",
        "# Imprimir texto\n",
        "print(\"- Resumen:\\n\", respuesta.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "et44VTJMFuWq",
        "outputId": "468ae47d-983f-46b9-ecf6-66ff929a100b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- Resumen:\n",
            " Ayer, en el subte D, una señora se descompuso en medio del calor y la multitud. La rápida ayuda de los pasajeros y la pronta llegada de un empleado del subte y el SAME resaltaron la solidaridad en una situación tensa.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. **Clasificación de sentimiento**"
      ],
      "metadata": {
        "id": "SbDWmbhTE8zM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Armamos un prompt donde le pedimos al modelo que clasifique el texto según el sentimiento (positivo, negativo o neutral).\n",
        "# También le pedimos que justifique su respuesta. El texto original se inserta con f-string.\n",
        "prompt_sentimiento = f\"\"\"Clasificá el siguiente texto como positivo, negativo o neutral, y explicá por qué:\n",
        "\n",
        "Texto: {text_to_process}\n",
        "\"\"\"\n",
        "\n",
        "# Enviamos el prompt al modelo Gemini, especificando el modelo a usar con MODEL_ID.\n",
        "# El modelo procesará el contenido y devolverá una respuesta generada.\n",
        "respuesta = cliente.models.generate_content(model=MODEL_ID, contents=[prompt_sentimiento])\n",
        "\n",
        "# Imprimimos la respuesta del modelo, que debería incluir la clasificación del sentimiento y una breve explicación.\n",
        "print(\"\\n - Sentimiento:\\n\", respuesta.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1wjwtGSF-l4",
        "outputId": "7070df13-11ca-439b-bdae-2bd16fe97a2f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " - Sentimiento:\n",
            " La clasificación es **positiva**.\n",
            "\n",
            "**Explicación:**\n",
            "\n",
            "Si bien el texto describe una situación inicialmente incómoda (vagón lleno y calor) y luego preocupante (señora que se descompone), el enfoque principal recae en la **solidaridad y la rápida respuesta de la gente y las autoridades**.\n",
            "\n",
            "*   El texto resalta la ayuda inmediata que recibió la señora.\n",
            "*   Se menciona la pronta llegada del empleado del subte y su llamada al servicio de emergencias (SAME).\n",
            "*   Finalmente, el narrador expresa una **sensación positiva** a pesar de la situación tensa, debido a la solidaridad presenciada.\n",
            "\n",
            "Por lo tanto, aunque el evento inicial no es positivo, la **reacción positiva del narrador y el énfasis en la ayuda mutua** inclinan la balanza hacia una clasificación positiva.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. **Reconocimiento de Entidades Nombradas (NER)**"
      ],
      "metadata": {
        "id": "fxRk9KvvFDcv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos el prompt para pedirle a Gemini que extraiga y clasifique las entidades nombradas del texto.\n",
        "# El prompt solicita específicamente la extracción de personas, organizaciones, lugares y objetos.\n",
        "# Usamos f-string para incluir el texto que se va a procesar.\n",
        "prompt_ner = f\"\"\"Extraé todas las entidades nombradas del siguiente texto (personas, organizaciones, lugares, objetos) y clasificálas:\n",
        "\n",
        "Texto: {text_to_process}\n",
        "\"\"\"\n",
        "\n",
        "# Enviamos el prompt al modelo Gemini especificado en `MODEL_ID`.\n",
        "# El modelo generará el contenido de acuerdo a la solicitud realizada en el prompt.\n",
        "respuesta = cliente.models.generate_content(model=MODEL_ID, contents=[prompt_ner])\n",
        "\n",
        "# Imprimimos la respuesta del modelo, que debe contener las entidades nombradas extraídas y clasificadas.\n",
        "print(\"\\n Entidades nombradas:\\n\", respuesta.text)\n"
      ],
      "metadata": {
        "id": "C2LLerXSGOwP",
        "outputId": "e3d7ef54-7f48-4952-d9d0-24f75070613b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Entidades nombradas:\n",
            " Aquí están las entidades nombradas extraídas del texto, clasificadas según su tipo:\n",
            "\n",
            "*   **Lugares:**\n",
            "    *   Catedral (Estación de subte)\n",
            "    *   Palermo (Barrio)\n",
            "\n",
            "*   **Organizaciones:**\n",
            "    *   SAME (Sistema de Atención Médica de Emergencias)\n",
            "\n",
            "*   **Objetos:**\n",
            "    *   Subte D (Línea de subterráneo)\n",
            "\n"
          ]
        }
      ]
    }
  ]
}