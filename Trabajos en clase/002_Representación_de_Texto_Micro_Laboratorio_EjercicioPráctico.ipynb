{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# PUNTO 7. Micro-Laboratorio (Ejercicio Práctico)\n",
        "\n",
        "**Consigna:**\n",
        "\n",
        "Usando las `reviews` y las funciones de preprocesamiento de clases previas (o volviendo a procesarlas ahora):\n",
        "1.  Asegúrate de tener la lista de `reviews_preprocesadas` (cada elemento es un string con los lemas unidos por espacios). Si no la tenés, generála usando la función `preprocesar_texto_para_vectorizar` sobre las `reviews` originales.\n",
        "2.  **Crear Matriz BoW:**\n",
        "    *   Instancia un `CountVectorizer`.\n",
        "    *   Aplícalo a las `reviews_preprocesadas` usando `fit_transform()`.\n",
        "    *   Obtén el vocabulario (`get_feature_names_out()`).\n",
        "    *   Crea un DataFrame de Pandas para visualizar la matriz BoW.\n",
        "3.  **Crear Matriz TF-IDF:**\n",
        "    *   Instancia un `TfidfVectorizer`.\n",
        "    *   Aplícalo a las **mismas** `reviews_preprocesadas` usando `fit_transform()`.\n",
        "    *   **Importante:** Para comparar fácil, puedes pasarle el vocabulario aprendido por el CountVectorizer al TfidfVectorizer usando el argumento `vocabulary=`. O viceversa. La idea es que ambas matrices usen las mismas columnas en el mismo orden.\n",
        "    *   Crea un DataFrame de Pandas para visualizar la matriz TF-IDF (redondea los valores a 3 decimales).\n",
        "4.  **Analizar:**\n",
        "    *   Imprime ambas matrices.\n",
        "    *   Elige una o dos reviews. ¿Qué palabras tienen los pesos más altos en TF-IDF para esa review? ¿Coincide con lo que esperarías que sean las palabras clave de esa review?\n",
        "    *   Busca alguna palabra que tenga un conteo > 0 en BoW pero un peso TF-IDF relativamente bajo. ¿Por qué podría ser? (Pista: ¿aparece en muchas reviews?)."
      ],
      "metadata": {
        "id": "ANf9C4_AuURY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Preprocesamiento**"
      ],
      "metadata": {
        "id": "LoCv0b0EXEsQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re  # Módulo para trabajar con expresiones regulares (limpieza de texto).\n",
        "import nltk  # Toolkit de procesamiento de lenguaje natural.\n",
        "from nltk.corpus import stopwords  # Carga las \"stopwords\" (palabras vacías) de NLTK.\n",
        "from nltk.stem import SnowballStemmer  # Uso el stemmer Snowball para español (reducción de palabras a su raíz).\n",
        "from sklearn.feature_extraction.text import CountVectorizer  # Importamos el vectorizador BoW (bolsa de palabras) de scikit-learn.\n",
        "import pandas as pd  # Importamos pandas para manejar la matriz como DataFrame y visualizarla más lindo\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer  # Importamos el vectorizador TF-IDF desde scikit-learn."
      ],
      "metadata": {
        "id": "-OJY4Jr_XD1m"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')  # Descargar el listado de stopwords en español\n",
        "stop_words = set(stopwords.words('spanish'))  # Creamos un set de palabras vacías en español.\n",
        "stemmer = SnowballStemmer('spanish')  # Instanciamos el stemmer para español (convierte palabras a su raíz)."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2TTMQuAXcAU",
        "outputId": "274e94f8-b25c-44bb-bed6-bd5f1f93220e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Función de preprocesamiento: recibe un texto y devuelve una versión limpia, lematizada y lista para vectorizar ---\n",
        "\n",
        "def preprocesar_texto_para_vectorizar(texto):\n",
        "    texto = texto.lower()  # Paso 1: pasamos todo a minúsculas para uniformizar.\n",
        "    texto = re.sub(r\"[^\\w\\s]\", \"\", texto)  # Paso 2: eliminamos puntuación y caracteres raros.\n",
        "    tokens = texto.split()  # Paso 3: tokenizamos (separamos por espacios).\n",
        "    tokens = [stemmer.stem(palabra) for palabra in tokens if palabra not in stop_words]\n",
        "\n",
        "    # Paso 4: aplicamos stemming a cada palabra, ignorando las stopwords.\n",
        "    return \" \".join(tokens)  # Paso 5: volvemos a unir las palabras preprocesadas en un único string."
      ],
      "metadata": {
        "id": "xWeBWxcMXmGi"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Dataset de reviews original (cinco frases sobre películas/documentales) ---\n",
        "\n",
        "reviews = [\n",
        "    \"Una película emocionante con actuaciones brillantes. ¡Me encantó!\",\n",
        "    \"Muy aburrida y lenta. El guión era predecible y los actores no convencían.\",\n",
        "    \"Los efectos especiales fueron impresionantes, pero la historia dejaba mucho que desear.\",\n",
        "    \"¡Qué gran comedia! Me reí sin parar durante toda la película.\",\n",
        "    \"Un documental necesario que aborda temas importantes con profundidad y sensibilidad.\"\n",
        "]"
      ],
      "metadata": {
        "id": "5rxQecyytQiI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplicamos la función de preprocesamiento a cada review del dataset original\n",
        "reviews_preprocesadas = [preprocesar_texto_para_vectorizar(r) for r in reviews]"
      ],
      "metadata": {
        "id": "sxrGBa6RXxJD"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Matriz BoW**"
      ],
      "metadata": {
        "id": "ZmZ69_tvX4U8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Vectorización BoW (Bag of Words): transforma texto en una matriz de conteos de palabras ---\n",
        "\n",
        "vectorizer_bow = CountVectorizer()  # Instanciamos el vectorizador (sin parámetros extra: toma el vocabulario que aparece)\n",
        "matriz_bow = vectorizer_bow.fit_transform(reviews_preprocesadas)\n",
        "# Ajustamos (fit) y transformamos las reviews preprocesadas al formato BoW. Resultado: una matriz sparse (dispersa)."
      ],
      "metadata": {
        "id": "an8W901JYJM9"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulario = vectorizer_bow.get_feature_names_out()\n",
        "# Extraemos las palabras (features) del vocabulario aprendido, en el orden en que están en las columnas de la matriz."
      ],
      "metadata": {
        "id": "k_4OOXnqYfjA"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_bow = pd.DataFrame(matriz_bow.toarray(), columns=vocabulario)\n",
        "# Convertimos la matriz dispersa a un array denso (toarray), y lo envolvemos en un DataFrame para que sea legible."
      ],
      "metadata": {
        "id": "RBjGaKgEYh_c"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Matriz BoW:\")  # Título\n",
        "print(df_bow)  # Mostramos la matriz BoW completa con conteos por review y por palabra"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TevneryDYkKV",
        "outputId": "dc7bff4b-038b-4a51-fd74-af4b860dcee0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matriz BoW:\n",
            "   abord  aburr  actor  actuacion  brillant  comedi  convenc  dej  des  \\\n",
            "0      0      0      0          1         1       0        0    0    0   \n",
            "1      0      1      1          0         0       0        1    0    0   \n",
            "2      0      0      0          0         0       0        0    1    1   \n",
            "3      0      0      0          0         0       1        0    0    0   \n",
            "4      1      0      0          0         0       0        0    0    0   \n",
            "\n",
            "   documental  ...  lent  necesari  par  pelicul  predec  profund  rei  \\\n",
            "0           0  ...     0         0    0        1       0        0    0   \n",
            "1           0  ...     1         0    0        0       1        0    0   \n",
            "2           0  ...     0         0    0        0       0        0    0   \n",
            "3           0  ...     0         0    1        1       0        0    1   \n",
            "4           1  ...     0         1    0        0       0        1    0   \n",
            "\n",
            "   sensibil  tem  tod  \n",
            "0         0    0    0  \n",
            "1         0    0    0  \n",
            "2         0    0    0  \n",
            "3         0    0    1  \n",
            "4         1    1    0  \n",
            "\n",
            "[5 rows x 29 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "*Cada número indica cuántas veces aparece una palabra (columna) en una review (fila).*\n",
        "\n",
        "-- Breve interpretación:\n",
        "\n",
        "**Fila** = una review (hay 5).\n",
        "\n",
        "**Columna**= una palabra preprocesada (hay 29).\n",
        "\n",
        "Ej: En la review 0, la palabra \"actuacion\" aparece 1 vez, \"aburr\" aparece 0 veces.\n",
        "\n",
        "*Muchas celdas son ceros: es normal en matrices de texto porque no todas las palabras están en todas las reviews*\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "6pXzpbym6Z9-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Matriz TF-IDF**"
      ],
      "metadata": {
        "id": "pbyxlNHLZHob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer_tfidf = TfidfVectorizer(vocabulary=vocabulario)\n",
        "# Instanciamos el vectorizador TF-IDF, **forzando** a que use el mismo vocabulario que el CountVectorizer"
      ],
      "metadata": {
        "id": "L-kVO6YeZHLz"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matriz_tfidf = vectorizer_tfidf.fit_transform(reviews_preprocesadas)\n",
        "# Ajustamos (fit) y transformamos las reviews preprocesadas a su representación TF-IDF.\n",
        "# Devuelve una matriz dispersa con los pesos TF-IDF (cuánto \"pesa\" cada término según frecuencia y rareza).\n",
        "\n",
        "df_tfidf = pd.DataFrame(matriz_tfidf.toarray(), columns=vocabulario)\n",
        "# Convertimos la matriz dispersa a un array denso (toarray) y la envolvemos en un DataFrame para que sea legible.\n"
      ],
      "metadata": {
        "id": "9EoAl4TjZb_F"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_tfidf = df_tfidf.round(3)\n",
        "# Redondeamos los valores a 3 decimales para que no se vea una ensalada de floats"
      ],
      "metadata": {
        "id": "b85p_TosZjpd"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n Matriz TF-IDF:\")  # Título para distinguir que ahora viene la matriz TF-IDF.\n",
        "print(df_tfidf)  # Mostramos el DataFrame con los valores TF-IDF por review y por término."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqyuUkTtZnzv",
        "outputId": "a0662d5d-4c19-4abb-af7f-8e5c8fa75f42"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Matriz TF-IDF:\n",
            "   abord  aburr  actor  actuacion  brillant  comedi  convenc    dej    des  \\\n",
            "0  0.000  0.000  0.000      0.464     0.464   0.000    0.000  0.000  0.000   \n",
            "1  0.000  0.408  0.408      0.000     0.000   0.000    0.408  0.000  0.000   \n",
            "2  0.000  0.000  0.000      0.000     0.000   0.000    0.000  0.408  0.408   \n",
            "3  0.000  0.000  0.000      0.000     0.000   0.421    0.000  0.000  0.000   \n",
            "4  0.378  0.000  0.000      0.000     0.000   0.000    0.000  0.000  0.000   \n",
            "\n",
            "   documental  ...   lent  necesari    par  pelicul  predec  profund    rei  \\\n",
            "0       0.000  ...  0.000     0.000  0.000    0.374   0.000    0.000  0.000   \n",
            "1       0.000  ...  0.408     0.000  0.000    0.000   0.408    0.000  0.000   \n",
            "2       0.000  ...  0.000     0.000  0.000    0.000   0.000    0.000  0.000   \n",
            "3       0.000  ...  0.000     0.000  0.421    0.339   0.000    0.000  0.421   \n",
            "4       0.378  ...  0.000     0.378  0.000    0.000   0.000    0.378  0.000   \n",
            "\n",
            "   sensibil    tem    tod  \n",
            "0     0.000  0.000  0.000  \n",
            "1     0.000  0.000  0.000  \n",
            "2     0.000  0.000  0.000  \n",
            "3     0.000  0.000  0.421  \n",
            "4     0.378  0.378  0.000  \n",
            "\n",
            "[5 rows x 29 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "*Cada número representa cuánto \"pesa\" o importa una palabra (columna) en una review (fila), según:*\n",
        "\n",
        "**TF**: frecuencia en la review.\n",
        "\n",
        "**IDF**: rareza en el conjunto total (menos común = más peso).\n",
        "\n",
        "--- Interpretación rápida:\n",
        "+ Valor alto = palabra importante y poco frecuente en el resto.\n",
        "\n",
        "+ Valor bajo = palabra que aparece mucho o es irrelevante (como “película”).\n",
        "\n",
        "\n",
        "--- Ejemplo:\n",
        "+ En la review 0, \"actuacion\" y \"brillant\" tienen peso 0.464 → son claves en esa frase.\n",
        "\n",
        " \"pelicul\" aparece varias veces en muchas reviews, por eso tiene peso menor (ej: 0.374 o menos).\n",
        "\n",
        "\n",
        "*Esto refina el BoW: no es solo cuántas veces aparece una palabra, sino cuánto valor aporta al texto.*\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "52GZLjbc70Bk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Análisis cualitativo**"
      ],
      "metadata": {
        "id": "FhmdxkYMZzfH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Elegimos la review 0 (índice 0)\n",
        "print(\"\\n Palabras con mayor peso en TF-IDF para review 0:\")\n",
        "review_0 = df_tfidf.iloc[0]  # Extrae los pesos TF-IDF de la primera review\n",
        "print(review_0.sort_values(ascending=False).head(5))  # Muestra las 5 palabras con mayor peso\n",
        "\n",
        "# Buscar palabra con alto conteo en BoW pero bajo TF-IDF\n",
        "print(\"\\n Palabras frecuentes en BoW pero con bajo peso TF-IDF:\")\n",
        "frecuentes = (df_bow.sum(axis=0) > 0)  # Palabras que aparecen al menos una vez (más laxo)\n",
        "pesos_bajos = (df_tfidf.mean(axis=0) < 0.3)  # Umbral más alto para considerar \"bajo peso\"\n",
        "candidatas = df_bow.columns[frecuentes & pesos_bajos]  # Palabras frecuentes pero poco informativas\n",
        "print(candidatas.tolist())  # Imprime la lista de esas palabras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9mg9efT9jKx",
        "outputId": "ba41c2e7-6bc1-4ae8-bb91-65e5e02e7729"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Palabras con mayor peso en TF-IDF para review 0:\n",
            "brillant     0.464\n",
            "actuacion    0.464\n",
            "emocion      0.464\n",
            "encant       0.464\n",
            "pelicul      0.374\n",
            "Name: 0, dtype: float64\n",
            "\n",
            " Palabras frecuentes en BoW pero con bajo peso TF-IDF:\n",
            "['abord', 'aburr', 'actor', 'actuacion', 'brillant', 'comedi', 'convenc', 'dej', 'des', 'documental', 'efect', 'emocion', 'encant', 'especial', 'gran', 'guion', 'histori', 'import', 'impresion', 'lent', 'necesari', 'par', 'pelicul', 'predec', 'profund', 'rei', 'sensibil', 'tem', 'tod']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Las palabras con mayor peso **en TF-IDF** para la review 0 (brillant, actuacion, emocion, encant, pelicul) reflejan con precisión los conceptos clave de esa opinión positiva, ya que son términos distintivos que no se repiten tanto en otras reviews.*\n",
        "\n",
        "\n",
        "-\n",
        "\n",
        "*En contraste, se identificaron varias palabras que aparecen frecuentemente en el corpus (alto conteo **en BoW)** pero con bajo peso TF-IDF. Esto se debe a que, al estar presentes en **múltiples** textos, su valor como discriminador baja. Incluso algunas palabras que destacan en una review (como actuacion o emocion) pueden tener un promedio bajo de TF-IDF si están dispersas en el resto del conjunto.*"
      ],
      "metadata": {
        "id": "PyxpFnHe8zT1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "***Conclusión: TF-IDF permite resaltar lo más representativo de cada review individual, mientras que BoW muestra cantidad pero no relevancia.***\n",
        "\n"
      ],
      "metadata": {
        "id": "Cd-nuaxYASLy"
      }
    }
  ]
}