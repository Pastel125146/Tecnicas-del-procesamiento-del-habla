{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 8.Actividad libre (opcional si hay tiempo)\n",
        "\n",
        "Explor√° uno de los pipelines y dise√±√° tu propio experimento:\n",
        "\n",
        "- Prob√° frases con sarcasmo o jergas locales.\n",
        "- Resum√≠ un art√≠culo de Wikipedia.\n",
        "- Traduc√≠ algo complejo (tecnol√≥gico, po√©tico, etc.).\n",
        "- Complet√° una frase usando estilo formal o informal.\n",
        "\n",
        "Al final compartimos los hallazgos m√°s interesantes con el grupo üëÄ\n",
        "\n"
      ],
      "metadata": {
        "id": "gC5dHmTaaOO7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# *** Actividad libre - Aplicaciones con Hugging Face (tem√°tica: postres y cocina)***\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "pPt346CE7ZKO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalaci√≥n\n",
        "!pip install -q transformers\n",
        "\n",
        "#  Importar pipelines\n",
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "JrQjP4tF7h3U"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "***--- 1. An√°lisis de Sentimiento con sarcasmo y jergas locales ---***\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Hg6whlrD7qZ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imprime un t√≠tulo con formato para separar visualmente esta secci√≥n del resto\n",
        "print(\"\\n 1. Frases con sarcasmo y jergas locales\\n\")\n",
        "\n",
        "# Crea un pipeline de an√°lisis de sentimiento usando el modelo BETO entrenado en espa√±ol\n",
        "sentiment = pipeline(\"sentiment-analysis\", model=\"finiteautomata/beto-sentiment-analysis\")\n",
        "\n",
        "# Lista de frases que contienen sarcasmo o jergas coloquiales relacionadas con postres\n",
        "frases_sarcasticas = [\n",
        "    \"Riqu√≠simo el flan, si te gusta el gusto a cart√≥n mojado.\",           # Sarcasmo negativo\n",
        "    \"Le met√≠ dulce de leche hasta por las dudas, qued√≥ un manjar.\",       # Jerga positiva\n",
        "    \"¬°Posta que esta torta te devuelve la fe en la vida!\",                # Expresi√≥n emocional\n",
        "    \"Claro, una delicia‚Ä¶ si te gusta masticar cemento.\",                  # Sarcasmo fuerte\n",
        "    \"Este cheesecake est√° tan bueno que me hizo olvidar a mi ex.\"         # Hiperbole positiva\n",
        "]\n",
        "\n",
        "# Itera sobre cada frase de la lista para analizar su sentimiento\n",
        "for frase in frases_sarcasticas:\n",
        "    resultado = sentiment(frase)[0]  # Aplica el modelo a la frase y extrae el primer resultado (label y score)\n",
        "\n",
        "    # Imprime la frase original, el sentimiento detectado (Positivo o Negativo) y la probabilidad asociada\n",
        "    print(f\"'{frase}' ‚Üí {resultado['label']} ({resultado['score']:.2f})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DRXRSLa-L7R",
        "outputId": "21574a3c-60d8-43f4-c183-b98b766eac32"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " 1. Frases con sarcasmo y jergas locales\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'Riqu√≠simo el flan, si te gusta el gusto a cart√≥n mojado.' ‚Üí POS (0.93)\n",
            "'Le met√≠ dulce de leche hasta por las dudas, qued√≥ un manjar.' ‚Üí POS (1.00)\n",
            "'¬°Posta que esta torta te devuelve la fe en la vida!' ‚Üí POS (1.00)\n",
            "'Claro, una delicia‚Ä¶ si te gusta masticar cemento.' ‚Üí NEU (1.00)\n",
            "'Este cheesecake est√° tan bueno que me hizo olvidar a mi ex.' ‚Üí POS (1.00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Muestra c√≥mo el modelo clasifica las frases con sarcasmo o jergas locales seg√∫n su sentimiento. La mayor√≠a de las frases son **clasificadas como positivas** (POS), incluso si el tono es sarc√°stico, con una alta certeza en la clasificaci√≥n (como 1.00). Sin embargo, una frase, \"Claro, una delicia‚Ä¶ si te gusta masticar cemento\", es clasificada como neutral (NEU), probablemente porque el sarcasmo no fue suficientemente marcado para ser detectado como negativo*"
      ],
      "metadata": {
        "id": "BRrT9MnvAZfb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "***--- 2. Resumen de un art√≠culo de Wikipedia sobre cocina ---***\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "vUD9gIdl8Gut"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imprime un t√≠tulo con formato para separar esta secci√≥n del resto\n",
        "print(\"\\n 2. Resumen de art√≠culo de Wikipedia\\n\")\n",
        "\n",
        "# Crea un pipeline de resumen de texto usando el modelo mT5 entrenado para varios idiomas, incluido el espa√±ol\n",
        "summarizer = pipeline(\n",
        "    \"summarization\",  # Especifica que el pipeline es para resumen de texto\n",
        "    model=\"csebuetnlp/mT5_multilingual_XLSum\",  # Especifica el modelo mT5, adecuado para resumen en varios idiomas\n",
        "    tokenizer=\"csebuetnlp/mT5_multilingual_XLSum\"  # Especifica el tokenizador que debe usarse con el modelo\n",
        ")\n",
        "\n",
        "# Define un texto largo que se quiere resumir, en este caso, sobre la chocotorta, un postre argentino\n",
        "texto_largo = \"\"\"\n",
        "La chocotorta es un postre t√≠pico de Argentina que se prepara sin cocci√≥n.\n",
        "Se compone de capas de galletitas de chocolate humedecidas en caf√© o leche, intercaladas con una mezcla de queso crema y dulce de leche.\n",
        "Es un postre f√°cil, econ√≥mico y muy popular en celebraciones familiares.\n",
        "Su creaci√≥n se le atribuye a una publicista argentina en la d√©cada de 1980.\n",
        "\"\"\"\n",
        "\n",
        "# Utiliza el pipeline para generar el resumen del texto, estableciendo l√≠mites de longitud para el resumen\n",
        "resumen = summarizer(texto_largo, max_length=50, min_length=20, do_sample=False)\n",
        "# max_length=50 establece un l√≠mite de 50 palabras como longitud m√°xima para el resumen\n",
        "# min_length=20 garantiza que el resumen no sea m√°s corto de 20 palabras\n",
        "# do_sample=False significa que no se utilizar√° un muestreo aleatorio, lo que da un resumen determin√≠stico\n",
        "\n",
        "# Imprime el resumen generado\n",
        "print(\" Resumen generado:\\n\", resumen[0]['summary_text'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qapaMCWJ-oBS",
        "outputId": "2208b285-b8d6-4a50-c7f4-8efebaea020f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " 2. Resumen de art√≠culo de Wikipedia\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  warnings.warn(\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Resumen generado:\n",
            " La choco Torta es un postre t√≠pico de Argentina que se prepara sin cocci√≥n.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "  *Resumi√≥ con √©xito el texto largo sobre la chocotorta, un postre argentino. El resumen generado es corto, destacando los puntos clave del texto original, como el hecho de que es un postre f√°cil, econ√≥mico y popular, y que no requiere cocci√≥n. El resultado demuestra c√≥mo el pipeline de resumen puede condensar textos largos sin perder detalles importantes.*"
      ],
      "metadata": {
        "id": "lj636oaIAspr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "***--- 3. Traducci√≥n de texto culinario complejo (po√©tico y t√©cnico) ---***\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "v371jTPx9ENh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imprime un t√≠tulo con formato para separar esta secci√≥n del resto\n",
        "print(\"\\n 3. Traducci√≥n de texto complejo (ES ‚Üí EN)\\n\")\n",
        "\n",
        "# Crea un pipeline de traducci√≥n usando el modelo preentrenado Helsinki-NLP/opus-mt-es-en que traduce de espa√±ol a ingl√©s\n",
        "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-es-en\")\n",
        "\n",
        "# Define una frase po√©tica en espa√±ol que se va a traducir al ingl√©s\n",
        "texto_poetico = \"El merengue debe ser tan firme que pueda sostener tus sue√±os sin caerse.\"\n",
        "\n",
        "# Define una frase t√©cnica en espa√±ol relacionada con cocina que tambi√©n se va a traducir al ingl√©s\n",
        "texto_tecnico = \"La emulsi√≥n perfecta entre la yema y el aceite es clave para una mayonesa brillante.\"\n",
        "\n",
        "# Traducir el texto po√©tico usando el pipeline, y extraer el texto traducido del resultado\n",
        "trad_poetico = translator(texto_poetico)[0]['translation_text']\n",
        "\n",
        "# Traducir el texto t√©cnico usando el pipeline, y extraer el texto traducido del resultado\n",
        "trad_tecnico = translator(texto_tecnico)[0]['translation_text']\n",
        "\n",
        "# Imprime la traducci√≥n del texto po√©tico al ingl√©s\n",
        "print(\"- Po√©tico:\\n\", trad_poetico)\n",
        "\n",
        "# Imprime la traducci√≥n del texto t√©cnico al ingl√©s\n",
        "print(\"- T√©cnico:\\n\", trad_tecnico)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpMDxV28_Buy",
        "outputId": "cd78a6ef-c053-4140-e9b9-b43283287030"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " 3. Traducci√≥n de texto complejo (ES ‚Üí EN)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/models/marian/tokenization_marian.py:177: UserWarning: Recommended: pip install sacremoses.\n",
            "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- Po√©tico:\n",
            " The meringue must be so firm that it can hold your dreams without falling.\n",
            "- T√©cnico:\n",
            " The perfect emulsion between yolk and oil is key to a bright mayonnaise.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Tradujo correctamente dos tipos de frases en espa√±ol al ingl√©s: una po√©tica y una t√©cnica. La traducci√≥n mantiene el sentido y estilo de cada oraci√≥n: la primera conserva el tono metaf√≥rico sobre el merengue, y la segunda transmite con precisi√≥n una explicaci√≥n t√©cnica sobre la mayonesa. Esto demuestra que el modelo puede adaptarse bien al contexto y nivel de lenguaje, incluso en dominios distintos como gastronom√≠a y poes√≠a.*"
      ],
      "metadata": {
        "id": "xgeCYSVGBAED"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "***--- 4. Generaci√≥n de texto: estilo formal vs informal ---***\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "lhUQdcVg9gXi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1Nd_mvv3JKA",
        "outputId": "13ce27b8-26c6-4792-cbf2-1fcaa2132c84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " 4. Completaci√≥n de frase (formal vs informal)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- Formal:\n",
            " Para lograr una mousse de chocolate perfecta, es fundamental contar con un buen calzado. \n",
            "- Informal:\n",
            " Si quer√©s que la mousse te quede piola, lo que ten√©s que hacer es visitar a los distribuidores y ver que la mousse es una de las mejores marcas de las que puedes ver en el mercado, pero tambi√©n lo que necesitas es que te entrelace a los distribuidores y ver que la mousse es una de las mejores que hay. \n"
          ]
        }
      ],
      "source": [
        "# Imprime un t√≠tulo con formato para separar esta secci√≥n del resto\n",
        "print(\"\\n 4. Completaci√≥n de frase (formal vs informal)\\n\")\n",
        "\n",
        "# Crea un pipeline de generaci√≥n de texto usando el modelo preentrenado PlanTL-GOB-ES/gpt2-base-bne (un modelo GPT-2 adaptado al espa√±ol)\n",
        "generator = pipeline(\"text-generation\", model=\"PlanTL-GOB-ES/gpt2-base-bne\")\n",
        "\n",
        "# Define un \"prompt\" formal para generar la continuaci√≥n de la frase de manera m√°s seria y t√©cnica\n",
        "prompt_formal = \"Para lograr una mousse de chocolate perfecta, es fundamental\"\n",
        "\n",
        "# Define un \"prompt\" informal para generar la continuaci√≥n de la frase de manera m√°s relajada y coloquial\n",
        "prompt_informal = \"Si quer√©s que la mousse te quede piola, lo que ten√©s que hacer es\"\n",
        "\n",
        "# Genera una continuaci√≥n para el prompt formal utilizando el generador de texto, limitando la longitud m√°xima a 50 palabras y obteniendo una √∫nica secuencia de salida\n",
        "gen_formal = generator(prompt_formal, max_length=50, num_return_sequences=1)[0]['generated_text']\n",
        "\n",
        "# Genera una continuaci√≥n para el prompt informal utilizando el generador de texto, limitando la longitud m√°xima a 50 palabras y obteniendo una √∫nica secuencia de salida\n",
        "gen_informal = generator(prompt_informal, max_length=50, num_return_sequences=1)[0]['generated_text']\n",
        "\n",
        "# Imprime la continuaci√≥n generada para el \"prompt\" formal, mostrando c√≥mo contin√∫a la frase de manera m√°s seria\n",
        "print(\"- Formal:\\n\", gen_formal)\n",
        "\n",
        "# Imprime la continuaci√≥n generada para el \"prompt\" informal, mostrando c√≥mo contin√∫a la frase de manera m√°s coloquial\n",
        "print(\"- Informal:\\n\", gen_informal)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Completaci√≥n de frase (formal vs informal):**\n",
        "\n",
        "El modelo gener√≥ continuaciones en dos estilos diferentes a partir de la misma frase inicial sobre una mousse de chocolate.\n",
        "\n",
        "* En el estilo **formal**, la respuesta fue coherente pero absurda: ‚Äúes fundamental contar con un buen calzado‚Äù, lo cual no tiene relaci√≥n con la cocina.\n",
        "\n",
        "+ En el estilo **informal**, la salida fue m√°s larga, coloquial y algo desorganizada, con repeticiones y frases confusas como ‚Äúver que la mousse es una de las mejores‚Äù.\n",
        "\n",
        "Esto muestra que el modelo distingue entre registros de lenguaje, aunque puede perder precisi√≥n tem√°tica, sobre todo en el estilo informal. Ideal para ilustrar diferencias de tono, pero no tanto para coherencia en cocina."
      ],
      "metadata": {
        "id": "EhyFubvRBSqV"
      }
    }
  ]
}
